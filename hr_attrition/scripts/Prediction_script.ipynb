{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23379514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nhr_attrition_clean_pipeline.py\\n\\nClean pipeline:\\n - Loads hr_attrition.csv\\n - Drops unwanted columns\\n - Protects against leakage (keep EmployeeNumber aside, drop any feature identical to target)\\n - Preprocess (impute, scale, one-hot) inside a Pipeline\\n - Train/Test split (stratified)\\n - Train Logistic Regression & RandomForest (class_weight='balanced')\\n - Evaluate on test set\\n - Retrain models on full data for final predictions for all employees\\n - KMeans clustering on preprocessed full data\\n - Export CSVs for Tableau and save joblib models\\n\\nRequirements:\\n pip install pandas scikit-learn joblib matplotlib\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "hr_attrition_clean_pipeline.py\n",
    "\n",
    "Clean pipeline:\n",
    " - Loads hr_attrition.csv\n",
    " - Drops unwanted columns\n",
    " - Protects against leakage (keep EmployeeNumber aside, drop any feature identical to target)\n",
    " - Preprocess (impute, scale, one-hot) inside a Pipeline\n",
    " - Train/Test split (stratified)\n",
    " - Train Logistic Regression & RandomForest (class_weight='balanced')\n",
    " - Evaluate on test set\n",
    " - Retrain models on full data for final predictions for all employees\n",
    " - KMeans clustering on preprocessed full data\n",
    " - Export CSVs for Tableau and save joblib models\n",
    "\n",
    "Requirements:\n",
    " pip install pandas scikit-learn joblib matplotlib\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e70ae450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report, average_precision_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bbfdf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1470 rows from hr_attrition.csv\n",
      "Found employee ID column: EmployeeNumber\n"
     ]
    }
   ],
   "source": [
    "# ---------- USER SETTINGS ----------\n",
    "INPUT_CSV = \"hr_attrition.csv\"\n",
    "OUTPUT_DIR = Path(\"model_outputs_clean\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 442\n",
    "TEST_SIZE = 0.30\n",
    "N_CLUSTERS = 4\n",
    "# -----------------------------------\n",
    "\n",
    "# ---------- Columns (use/drop) ----------\n",
    "use_cols = [\n",
    "    \"Age\", \"Department\", \"JobRole\", \"JobLevel\", \"DistanceFromHome\",\n",
    "    \"BusinessTravel\", \"OverTime\", \"MonthlyIncome\", \"PercentSalaryHike\",\n",
    "    \"PerformanceRating\", \"TotalWorkingYears\", \"YearsAtCompany\", \"YearsInCurrentRole\",\n",
    "    \"YearsSinceLastPromotion\", \"YearsWithCurrManager\", \"JobSatisfaction\",\n",
    "    \"EnvironmentSatisfaction\", \"RelationshipSatisfaction\", \"WorkLifeBalance\",\n",
    "    \"EducationField\", \"Education\", \"Gender\", \"MaritalStatus\", \"StockOptionLevel\",\n",
    "    # keep extra potentially useful fields you had\n",
    "    \"TrainingTimesLastYear\", \"NumCompaniesWorked\", \"JobInvolvement\"\n",
    "]\n",
    "\n",
    "drop_cols = [\n",
    "    \"Random Number\", \"EmployeeCount\", \"DailyRate\", \"HourlyRate\", \"MonthlyRate\",\n",
    "    \"Over18\", \"StandardHours\", \"attrition date\"\n",
    "    # DO NOT drop EmployeeNumber here because we'll keep it aside if present\n",
    "]\n",
    "\n",
    "# ---------- Load ----------\n",
    "df_raw = pd.read_csv(INPUT_CSV)\n",
    "print(f\"Loaded {len(df_raw)} rows from {INPUT_CSV}\")\n",
    "\n",
    "# Keep EmployeeNumber if present (for re-attachment) but don't use in modeling\n",
    "employee_id_col = None\n",
    "for candidate in [\"EmployeeNumber\", \"EmployeeId\", \"Employee_ID\", \"EmpID\"]:\n",
    "    if candidate in df_raw.columns:\n",
    "        employee_id_col = candidate\n",
    "        break\n",
    "\n",
    "if employee_id_col:\n",
    "    print(f\"Found employee ID column: {employee_id_col}\")\n",
    "    df_raw[employee_id_col] = df_raw[employee_id_col].astype(str).str.strip()\n",
    "else:\n",
    "    print(\"No employee ID column found. Predictions will not include an ID column.\")\n",
    "\n",
    "# Drop columns explicitly\n",
    "for c in drop_cols:\n",
    "    if c in df_raw.columns:\n",
    "        df_raw.drop(columns=c, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d5f6735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns kept for processing: ['EmployeeNumber', 'Attrition', 'Age', 'Department', 'JobRole', 'JobLevel', 'DistanceFromHome', 'BusinessTravel', 'OverTime', 'MonthlyIncome', 'PercentSalaryHike', 'PerformanceRating', 'TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager', 'JobSatisfaction', 'EnvironmentSatisfaction', 'RelationshipSatisfaction', 'WorkLifeBalance', 'EducationField', 'Education', 'Gender', 'MaritalStatus', 'StockOptionLevel', 'TrainingTimesLastYear', 'NumCompaniesWorked', 'JobInvolvement']\n"
     ]
    }
   ],
   "source": [
    "# Keep only the use_cols that exist + Attrition + employee id (if present)\n",
    "present_use = [c for c in use_cols if c in df_raw.columns]\n",
    "cols_to_keep = [\"Attrition\"] + present_use\n",
    "if employee_id_col:\n",
    "    # keep employee id in the master dataframe\n",
    "    cols_to_keep = [employee_id_col] + cols_to_keep\n",
    "\n",
    "df = df_raw[cols_to_keep].copy()\n",
    "print(\"Columns kept for processing:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b39c01f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attrition distribution: {0: 1233, 1: 237}\n"
     ]
    }
   ],
   "source": [
    "# ---------- Target encoding ----------\n",
    "if \"Attrition\" not in df.columns:\n",
    "    raise ValueError(\"Attrition column not found.\")\n",
    "\n",
    "df[\"Attrition\"] = df[\"Attrition\"].astype(str).str.strip()\n",
    "df = df[df[\"Attrition\"].notna()].copy()\n",
    "df[\"Attrition_bin\"] = df[\"Attrition\"].apply(lambda x: 1 if str(x).lower().startswith(\"y\") else 0)\n",
    "print(\"Attrition distribution:\", df[\"Attrition_bin\"].value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b99965f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Prevent obvious leakage ----------\n",
    "# 1) Check features identical to target -> drop them\n",
    "candidate_features = [c for c in df.columns if c not in [\"Attrition\", \"Attrition_bin\", employee_id_col]]\n",
    "identical_to_target = []\n",
    "for c in candidate_features:\n",
    "    try:\n",
    "        if df[c].dtype != object and df[c].equals(df[\"Attrition_bin\"]):\n",
    "            identical_to_target.append(c)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "if identical_to_target:\n",
    "    print(\"Dropping features identical to the target (leakage):\", identical_to_target)\n",
    "    df.drop(columns=identical_to_target, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "148775b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature sets:\n",
      "  numeric: ['Age', 'DistanceFromHome', 'MonthlyIncome', 'PercentSalaryHike', 'TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager', 'StockOptionLevel', 'TrainingTimesLastYear', 'NumCompaniesWorked']\n",
      "  ordinal: ['PerformanceRating', 'JobLevel', 'JobSatisfaction', 'EnvironmentSatisfaction', 'RelationshipSatisfaction', 'WorkLifeBalance', 'JobInvolvement']\n",
      "  categorical: ['Education', 'Department', 'JobRole', 'BusinessTravel', 'OverTime', 'EducationField', 'Gender', 'MaritalStatus']\n",
      "  total features used: 27\n"
     ]
    }
   ],
   "source": [
    "# ---------- Feature lists: adaptive detection ----------\n",
    "numeric_candidates = [\n",
    "    \"Age\", \"DistanceFromHome\", \"MonthlyIncome\", \"PercentSalaryHike\",\n",
    "    \"TotalWorkingYears\", \"YearsAtCompany\", \"YearsInCurrentRole\",\n",
    "    \"YearsSinceLastPromotion\", \"YearsWithCurrManager\", \"StockOptionLevel\",\n",
    "    \"TrainingTimesLastYear\", \"NumCompaniesWorked\" \n",
    "]\n",
    "ordinal_candidates = [\"PerformanceRating\", \"JobLevel\", \"Education\", \"JobSatisfaction\", \"EnvironmentSatisfaction\",\n",
    "                      \"RelationshipSatisfaction\", \"WorkLifeBalance\", \"JobInvolvement\"]\n",
    "cat_candidates = [\"Department\", \"JobRole\", \"BusinessTravel\", \"OverTime\",\n",
    "                  \"EducationField\", \"Gender\", \"MaritalStatus\"]\n",
    "\n",
    "numeric_candidates = [c for c in numeric_candidates if c in df.columns]\n",
    "ordinal_candidates = [c for c in ordinal_candidates if c in df.columns]\n",
    "cat_candidates = [c for c in cat_candidates if c in df.columns]\n",
    "\n",
    "# helper: numeric-like detection\n",
    "def is_numeric_like(series, thresh=0.9):\n",
    "    coerced = pd.to_numeric(series, errors=\"coerce\")\n",
    "    return coerced.notna().mean() >= thresh\n",
    "\n",
    "numeric_features = []\n",
    "ordinal_features = []\n",
    "cat_features = []\n",
    "\n",
    "for c in numeric_candidates:\n",
    "    if is_numeric_like(df[c]):\n",
    "        numeric_features.append(c)\n",
    "    else:\n",
    "        cat_features.append(c)\n",
    "\n",
    "for c in ordinal_candidates:\n",
    "    if is_numeric_like(df[c]):\n",
    "        ordinal_features.append(c)\n",
    "    else:\n",
    "        # if text education mapping is desired, map manually before running the script\n",
    "        cat_features.append(c)\n",
    "\n",
    "# add remaining categorical candidates\n",
    "for c in cat_candidates:\n",
    "    if c not in numeric_features + ordinal_features and c in df.columns:\n",
    "        cat_features.append(c)\n",
    "\n",
    "# final feature list\n",
    "feature_columns = numeric_features + ordinal_features + cat_features\n",
    "print(\"Final feature sets:\")\n",
    "print(\"  numeric:\", numeric_features)\n",
    "print(\"  ordinal:\", ordinal_features)\n",
    "print(\"  categorical:\", cat_features)\n",
    "print(\"  total features used:\", len(feature_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24191df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test sizes: 1029 441\n"
     ]
    }
   ],
   "source": [
    "# ---------- Prepare X and y and keep employee ids aligned ----------\n",
    "# Keep a copy of the employee id column aligned with df rows\n",
    "if employee_id_col:\n",
    "    df = df.reset_index(drop=True)\n",
    "    ids = df[employee_id_col].astype(str).reset_index(drop=True)\n",
    "else:\n",
    "    ids = pd.Series([None]*len(df))\n",
    "\n",
    "X = df[feature_columns].copy()\n",
    "y = df[\"Attrition_bin\"].copy()\n",
    "\n",
    "# ---------- Train/Test split (stratified) ----------\n",
    "X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(\n",
    "    X, y, ids, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "print(\"Train/test sizes:\", X_train.shape[0], X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4988fbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'DistanceFromHome', 'MonthlyIncome', 'PercentSalaryHike',\n",
       "       'TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole',\n",
       "       'YearsSinceLastPromotion', 'YearsWithCurrManager', 'StockOptionLevel',\n",
       "       'TrainingTimesLastYear', 'NumCompaniesWorked', 'PerformanceRating',\n",
       "       'JobLevel', 'JobSatisfaction', 'EnvironmentSatisfaction',\n",
       "       'RelationshipSatisfaction', 'WorkLifeBalance', 'JobInvolvement',\n",
       "       'Education', 'Department', 'JobRole', 'BusinessTravel', 'OverTime',\n",
       "       'EducationField', 'Gender', 'MaritalStatus'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fed71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Preprocessing pipelines (fit only on train inside pipeline) ----------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"ord\", ordinal_transformer, ordinal_features),\n",
    "    (\"cat\", categorical_transformer, cat_features)\n",
    "], remainder=\"drop\", sparse_threshold=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad71ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# helper to get feature names after transformation\n",
    "def get_feature_names_from_column_transformer(ct: ColumnTransformer):\n",
    "    names = []\n",
    "    for name, transformer, cols in ct.transformers_:\n",
    "        if name == \"remainder\":\n",
    "            continue\n",
    "        if isinstance(transformer, Pipeline) and \"ohe\" in transformer.named_steps:\n",
    "            ohe = transformer.named_steps[\"ohe\"]\n",
    "            cols_list = list(cols)\n",
    "            try:\n",
    "                names.extend(list(ohe.get_feature_names_out(cols_list)))\n",
    "            except Exception:\n",
    "                # fallback generic names for categories\n",
    "                for c in cols_list:\n",
    "                    names.append(c)\n",
    "        else:\n",
    "            names.extend(list(cols))\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c378045f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression on train set...\n",
      "Training Random Forest on train set...\n",
      "Logistic Regression (test): {'accuracy': 0.7437641723356009, 'precision': 0.3618421052631579, 'recall': 0.7746478873239436, 'f1': 0.49327354260089684, 'roc_auc': 0.8044156832889227, 'pr_auc': 0.6470101455104612}\n",
      "Random Forest (test): {'accuracy': 0.8616780045351474, 'precision': 0.8125, 'recall': 0.18309859154929578, 'f1': 0.2988505747126437, 'roc_auc': 0.8061857632280167, 'pr_auc': 0.5665101897464231}\n"
     ]
    }
   ],
   "source": [
    "# ---------- Build pipelines ----------\n",
    "pipe_lr = Pipeline(steps=[\n",
    "    (\"preproc\", preprocessor),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "pipe_rf = Pipeline(steps=[\n",
    "    (\"preproc\", preprocessor),\n",
    "    (\"clf\", RandomForestClassifier(n_estimators=200, class_weight=\"balanced\", random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "# ---------- Train on train set ----------\n",
    "print(\"Training Logistic Regression on train set...\")\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training Random Forest on train set...\")\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "# ---------- Evaluate on test set ----------\n",
    "pred_lr = pipe_lr.predict(X_test)\n",
    "proba_lr = pipe_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "pred_rf = pipe_rf.predict(X_test)\n",
    "proba_rf = pipe_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "lr_metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, pred_lr),\n",
    "    \"precision\": precision_score(y_test, pred_lr, zero_division=0),\n",
    "    \"recall\": recall_score(y_test, pred_lr, zero_division=0),\n",
    "    \"f1\": f1_score(y_test, pred_lr, zero_division=0),\n",
    "    \"roc_auc\": roc_auc_score(y_test, proba_lr),\n",
    "    \"pr_auc\": average_precision_score(y_test, proba_lr)\n",
    "}\n",
    "\n",
    "rf_metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, pred_rf),\n",
    "    \"precision\": precision_score(y_test, pred_rf, zero_division=0),\n",
    "    \"recall\": recall_score(y_test, pred_rf, zero_division=0),\n",
    "    \"f1\": f1_score(y_test, pred_rf, zero_division=0),\n",
    "    \"roc_auc\": roc_auc_score(y_test, proba_rf),\n",
    "    \"pr_auc\": average_precision_score(y_test, proba_rf)\n",
    "}\n",
    "\n",
    "print(\"Logistic Regression (test):\", lr_metrics)\n",
    "print(\"Random Forest (test):\", rf_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "250217a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote logistic_coefficients.csv\n",
      "Wrote rf_feature_importance.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_outputs_clean/random_forest_model_train.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# save test evaluation\n",
    "pd.DataFrame([lr_metrics, rf_metrics], index=[\"LogisticRegression\", \"RandomForest\"]).to_csv(OUTPUT_DIR / \"test_metrics.csv\")\n",
    "\n",
    "# ---------- Feature importances & coefficients mapping (use preprocessor fitted on train) ----------\n",
    "# get feature names by fitting preprocessor on X_train (we need feature names for importances)\n",
    "preprocessor_fitted = pipe_rf.named_steps[\"preproc\"]\n",
    "try:\n",
    "    feat_names_post = get_feature_names_from_column_transformer(preprocessor_fitted)\n",
    "except Exception:\n",
    "    feat_names_post = [f\"f{i}\" for i in range(pipe_rf.named_steps[\"clf\"].n_features_in_)]\n",
    "\n",
    "# Logistic coefficients\n",
    "try:\n",
    "    lr_coefs = pipe_lr.named_steps[\"clf\"].coef_[0]\n",
    "    df_lr_coef = pd.DataFrame({\"feature\": feat_names_post, \"coefficient\": lr_coefs})\n",
    "    df_lr_coef[\"abs_coef\"] = df_lr_coef[\"coefficient\"].abs()\n",
    "    df_lr_coef.sort_values(by=\"abs_coef\", ascending=False, inplace=True)\n",
    "    df_lr_coef.drop(columns=\"abs_coef\", inplace=True)\n",
    "    df_lr_coef.to_csv(OUTPUT_DIR / \"logistic_coefficients.csv\", index=False)\n",
    "    print(\"Wrote logistic_coefficients.csv\")\n",
    "except Exception as e:\n",
    "    print(\"Could not map LR coefficients:\", e)\n",
    "\n",
    "# Random Forest feature importance\n",
    "try:\n",
    "    rf_importances = pipe_rf.named_steps[\"clf\"].feature_importances_\n",
    "    df_rf_feat = pd.DataFrame({\"feature\": feat_names_post, \"importance\": rf_importances})\n",
    "    df_rf_feat.sort_values(by=\"importance\", ascending=False, inplace=True)\n",
    "    df_rf_feat.to_csv(OUTPUT_DIR / \"rf_feature_importance.csv\", index=False)\n",
    "    print(\"Wrote rf_feature_importance.csv\")\n",
    "except Exception as e:\n",
    "    print(\"Could not map RF importances:\", e)\n",
    "\n",
    "# Save models trained on train data (optional)\n",
    "joblib.dump(pipe_lr, OUTPUT_DIR / \"logistic_model_train.joblib\")\n",
    "joblib.dump(pipe_rf, OUTPUT_DIR / \"random_forest_model_train.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bcb4deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining models on full dataset for final scoring...\n",
      "Wrote full predictions to: /Users/ghazalayobi/portfolio_projects/hr_attrition/model_outputs_clean/attrition_predictions_all_employees.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_outputs_clean/random_forest_model_full.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---------- Retrain on FULL data for final predictions for all employees ----------\n",
    "print(\"Retraining models on full dataset for final scoring...\")\n",
    "\n",
    "# Rebuild preprocessor (fresh) -- but use same variable names for clarity\n",
    "preprocessor_full = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"ord\", ordinal_transformer, ordinal_features),\n",
    "    (\"cat\", categorical_transformer, cat_features)\n",
    "], remainder=\"drop\", sparse_threshold=0)\n",
    "\n",
    "pipe_lr_full = Pipeline(steps=[(\"preproc\", preprocessor_full),\n",
    "                               (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=RANDOM_STATE))])\n",
    "pipe_rf_full = Pipeline(steps=[(\"preproc\", preprocessor_full),\n",
    "                               (\"clf\", RandomForestClassifier(n_estimators=200, class_weight=\"balanced\", random_state=RANDOM_STATE))])\n",
    "\n",
    "pipe_lr_full.fit(X, y)\n",
    "pipe_rf_full.fit(X, y)\n",
    "\n",
    "proba_lr_all = pipe_lr_full.predict_proba(X)[:, 1]\n",
    "pred_lr_all = pipe_lr_full.predict(X)\n",
    "\n",
    "proba_rf_all = pipe_rf_full.predict_proba(X)[:, 1]\n",
    "pred_rf_all = pipe_rf_full.predict(X)\n",
    "\n",
    "# Add predictions back to original df aligned by index\n",
    "df_all = df.reset_index(drop=True).copy()\n",
    "if employee_id_col:\n",
    "    df_all[employee_id_col] = ids.values\n",
    "\n",
    "df_all[\"Predicted_Attrition_LR\"] = pred_lr_all\n",
    "df_all[\"Attrition_Probability_LR\"] = proba_lr_all\n",
    "df_all[\"Predicted_Attrition_RF\"] = pred_rf_all\n",
    "df_all[\"Attrition_Probability_RF\"] = proba_rf_all\n",
    "\n",
    "df_all[\"Predicted_Attrition_LR_label\"] = df_all[\"Predicted_Attrition_LR\"].map({1: \"Yes\", 0: \"No\"})\n",
    "df_all[\"Predicted_Attrition_RF_label\"] = df_all[\"Predicted_Attrition_RF\"].map({1: \"Yes\", 0: \"No\"})\n",
    "\n",
    "out_all = OUTPUT_DIR / \"attrition_predictions_all_employees.csv\"\n",
    "df_all.to_csv(out_all, index=False)\n",
    "print(\"Wrote full predictions to:\", out_all.resolve())\n",
    "\n",
    "# Save final models (pipelines fitted on full data)\n",
    "joblib.dump(pipe_lr_full, OUTPUT_DIR / \"logistic_model_full.joblib\")\n",
    "joblib.dump(pipe_rf_full, OUTPUT_DIR / \"random_forest_model_full.joblib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a454187e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing KMeans clustering on all employees (preprocessed features)...\n",
      "Wrote attrition_predictions_with_clusters.csv with cluster labels\n",
      "Wrote cluster_profiles.csv\n",
      "Wrote rf classification report and confusion matrix for test set\n",
      "All outputs written to /Users/ghazalayobi/portfolio_projects/hr_attrition/model_outputs_clean\n"
     ]
    }
   ],
   "source": [
    "# ---------- Clustering on full preprocessed data ----------\n",
    "print(\"Performing KMeans clustering on all employees (preprocessed features)...\")\n",
    "X_all_prep = pipe_rf_full.named_steps[\"preproc\"].transform(X)  # numpy array\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=RANDOM_STATE, n_init=20)\n",
    "clusters = kmeans.fit_predict(X_all_prep)\n",
    "\n",
    "df_all[\"Cluster\"] = clusters\n",
    "df_all.to_csv(OUTPUT_DIR / \"attrition_predictions_with_clusters.csv\", index=False)\n",
    "print(\"Wrote attrition_predictions_with_clusters.csv with cluster labels\")\n",
    "\n",
    "# Cluster profiles\n",
    "profile_cols = numeric_features + ordinal_features\n",
    "existing_profile_cols = [c for c in profile_cols if c in df_all.columns]\n",
    "cluster_profile = df_all.groupby(\"Cluster\")[existing_profile_cols].mean().round(3)\n",
    "cluster_profile[\"count\"] = df_all.groupby(\"Cluster\").size()\n",
    "cluster_profile.to_csv(OUTPUT_DIR / \"cluster_profiles.csv\")\n",
    "print(\"Wrote cluster_profiles.csv\")\n",
    "\n",
    "# ---------- Confusion/Classification report on test set ----------\n",
    "pd.DataFrame(classification_report(y_test, pred_rf, output_dict=True)).transpose().to_csv(OUTPUT_DIR / \"rf_classification_report_test.csv\")\n",
    "pd.DataFrame(confusion_matrix(y_test, pred_rf), index=[\"Actual_0\",\"Actual_1\"], columns=[\"Pred_0\",\"Pred_1\"]).to_csv(OUTPUT_DIR / \"rf_confusion_matrix_test.csv\")\n",
    "print(\"Wrote rf classification report and confusion matrix for test set\")\n",
    "\n",
    "print(\"All outputs written to\", OUTPUT_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af395b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final predictions saved: /Users/ghazalayobi/portfolio_projects/hr_attrition/model_outputs_clean/attrition_predictions_all_employees.csv (rows: 1470)\n"
     ]
    }
   ],
   "source": [
    "# Keep a clean copy of EmployeeNumber (not used in training)\n",
    "employee_ids = df_raw[\"EmployeeNumber\"].reset_index(drop=True)\n",
    "\n",
    "# Create a final dataframe with all features and predictions\n",
    "df_final = df.reset_index(drop=True).copy()\n",
    "df_final[\"EmployeeNumber\"] = employee_ids\n",
    "\n",
    "# Add model predictions\n",
    "df_final[\"Predicted_Attrition_LR\"] = pred_lr_all\n",
    "df_final[\"Attrition_Probability_LR\"] = proba_lr_all\n",
    "df_final[\"Predicted_Attrition_RF\"] = pred_rf_all\n",
    "df_final[\"Attrition_Probability_RF\"] = proba_rf_all\n",
    "\n",
    "# Add cluster labels if you did clustering\n",
    "df_final[\"Cluster\"] = clusters\n",
    "\n",
    "# Optional: create human-readable labels\n",
    "df_final[\"Predicted_Attrition_LR_label\"] = df_final[\"Predicted_Attrition_LR\"].map({1: \"Yes\", 0: \"No\"})\n",
    "df_final[\"Predicted_Attrition_RF_label\"] = df_final[\"Predicted_Attrition_RF\"].map({1: \"Yes\", 0: \"No\"})\n",
    "\n",
    "# Save for Tableau\n",
    "output_all_path = OUTPUT_DIR / \"attrition_predictions_all_employees.csv\"\n",
    "df_final.to_csv(output_all_path, index=False)\n",
    "print(f\"✅ Final predictions saved: {output_all_path.resolve()} (rows: {len(df_final)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e22fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
